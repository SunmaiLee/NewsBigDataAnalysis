{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "komoran = Komoran()\n",
    "kkma = Kkma()\n",
    "okt = Okt()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-     For Korean words\n",
    "\n",
    "\n",
    "path_dir = '/home/minkh/Downloads/twitter/'\n",
    "file_list = os.listdir(path_dir)\n",
    "file_list.sort()\n",
    "\n",
    "filenames =[]\n",
    "for i in range(len(file_list)):\n",
    "    filenames.append(file_list[i])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitter_20180701.json',\n",
       " 'twitter_20180702.json',\n",
       " 'twitter_20180703.json',\n",
       " 'twitter_20180704.json',\n",
       " 'twitter_20180705.json',\n",
       " 'twitter_20180706.json',\n",
       " 'twitter_20180707.json',\n",
       " 'twitter_20180708.json',\n",
       " 'twitter_20180709.json',\n",
       " 'twitter_20180710.json',\n",
       " 'twitter_20180711.json',\n",
       " 'twitter_20180712.json',\n",
       " 'twitter_20180713.json',\n",
       " 'twitter_20180714.json',\n",
       " 'twitter_20180715.json',\n",
       " 'twitter_20180716.json',\n",
       " 'twitter_20180717.json',\n",
       " 'twitter_20180718.json',\n",
       " 'twitter_20180719.json',\n",
       " 'twitter_20180720.json',\n",
       " 'twitter_20180721.json',\n",
       " 'twitter_20180722.json',\n",
       " 'twitter_20180723.json',\n",
       " 'twitter_20180724.json',\n",
       " 'twitter_20180725.json',\n",
       " 'twitter_20180726.json',\n",
       " 'twitter_20180727.json',\n",
       " 'twitter_20180728.json',\n",
       " 'twitter_20180729.json',\n",
       " 'twitter_20180730.json',\n",
       " 'twitter_20180731.json',\n",
       " 'twitter_20180801.json',\n",
       " 'twitter_20180802.json',\n",
       " 'twitter_20180803.json',\n",
       " 'twitter_20180804.json',\n",
       " 'twitter_20180805.json',\n",
       " 'twitter_20180806.json',\n",
       " 'twitter_20180807.json',\n",
       " 'twitter_20180808.json',\n",
       " 'twitter_20180809.json',\n",
       " 'twitter_20180810.json',\n",
       " 'twitter_20180811.json',\n",
       " 'twitter_20180812.json',\n",
       " 'twitter_20180813.json',\n",
       " 'twitter_20180814.json',\n",
       " 'twitter_20180815.json',\n",
       " 'twitter_20180816.json',\n",
       " 'twitter_20180817.json',\n",
       " 'twitter_20180818.json',\n",
       " 'twitter_20180819.json',\n",
       " 'twitter_20180820.json',\n",
       " 'twitter_20180821.json',\n",
       " 'twitter_20180822.json',\n",
       " 'twitter_20180823.json',\n",
       " 'twitter_20180824.json',\n",
       " 'twitter_20180825.json',\n",
       " 'twitter_20180826.json',\n",
       " 'twitter_20180827.json',\n",
       " 'twitter_20180828.json',\n",
       " 'twitter_20180829.json',\n",
       " 'twitter_20180830.json',\n",
       " 'twitter_20180831.json',\n",
       " 'twitter_20180901.json',\n",
       " 'twitter_20180902.json',\n",
       " 'twitter_20180903.json',\n",
       " 'twitter_20180904.json',\n",
       " 'twitter_20180905.json',\n",
       " 'twitter_20180906.json',\n",
       " 'twitter_20180907.json',\n",
       " 'twitter_20180908.json',\n",
       " 'twitter_20180909.json',\n",
       " 'twitter_20180910.json',\n",
       " 'twitter_20180911.json',\n",
       " 'twitter_20180912.json',\n",
       " 'twitter_20180913.json',\n",
       " 'twitter_20180914.json',\n",
       " 'twitter_20180915.json',\n",
       " 'twitter_20180916.json',\n",
       " 'twitter_20180917.json',\n",
       " 'twitter_20180918.json',\n",
       " 'twitter_20180919.json',\n",
       " 'twitter_20180920.json',\n",
       " 'twitter_20180921.json',\n",
       " 'twitter_20180922.json',\n",
       " 'twitter_20180923.json',\n",
       " 'twitter_20180924.json',\n",
       " 'twitter_20180925.json',\n",
       " 'twitter_20180926.json',\n",
       " 'twitter_20180927.json',\n",
       " 'twitter_20180928.json',\n",
       " 'twitter_20180929.json',\n",
       " 'twitter_20180930.json',\n",
       " 'twitter_20181001.json',\n",
       " 'twitter_20181002.json',\n",
       " 'twitter_20181003.json',\n",
       " 'twitter_20181004.json',\n",
       " 'twitter_20181005.json',\n",
       " 'twitter_20181006.json',\n",
       " 'twitter_20181007.json',\n",
       " 'twitter_20181008.json',\n",
       " 'twitter_20181009.json',\n",
       " 'twitter_20181010.json',\n",
       " 'twitter_20181011.json',\n",
       " 'twitter_20181012.json',\n",
       " 'twitter_20181013.json',\n",
       " 'twitter_20181014.json',\n",
       " 'twitter_20181015.json',\n",
       " 'twitter_20181016.json',\n",
       " 'twitter_20181017.json',\n",
       " 'twitter_20181018.json',\n",
       " 'twitter_20181019.json',\n",
       " 'twitter_20181020.json',\n",
       " 'twitter_20181021.json',\n",
       " 'twitter_20181022.json',\n",
       " 'twitter_20181023.json',\n",
       " 'twitter_20181024.json',\n",
       " 'twitter_20181025.json',\n",
       " 'twitter_20181026.json',\n",
       " 'twitter_20181027.json',\n",
       " 'twitter_20181028.json',\n",
       " 'twitter_20181029.json',\n",
       " 'twitter_20181030.json',\n",
       " 'twitter_20181031.json',\n",
       " 'twitter_20181101.json',\n",
       " 'twitter_20181102.json',\n",
       " 'twitter_20181103.json',\n",
       " 'twitter_20181104.json',\n",
       " 'twitter_20181105.json',\n",
       " 'twitter_20181106.json',\n",
       " 'twitter_20181107.json',\n",
       " 'twitter_20181108.json',\n",
       " 'twitter_20181109.json',\n",
       " 'twitter_20181110.json',\n",
       " 'twitter_20181111.json',\n",
       " 'twitter_20181112.json',\n",
       " 'twitter_20181113.json',\n",
       " 'twitter_20181114.json',\n",
       " 'twitter_20181115.json',\n",
       " 'twitter_20181116.json',\n",
       " 'twitter_20181117.json',\n",
       " 'twitter_20181118.json',\n",
       " 'twitter_20181119.json',\n",
       " 'twitter_20181120.json',\n",
       " 'twitter_20181121.json',\n",
       " 'twitter_20181122.json',\n",
       " 'twitter_20181123.json',\n",
       " 'twitter_20181124.json',\n",
       " 'twitter_20181125.json',\n",
       " 'twitter_20181126.json',\n",
       " 'twitter_20181127.json',\n",
       " 'twitter_20181128.json',\n",
       " 'twitter_20181129.json',\n",
       " 'twitter_20181130.json',\n",
       " 'twitter_20181201.json',\n",
       " 'twitter_20181202.json',\n",
       " 'twitter_20181203.json',\n",
       " 'twitter_20181204.json',\n",
       " 'twitter_20181205.json',\n",
       " 'twitter_20181206.json',\n",
       " 'twitter_20181207.json',\n",
       " 'twitter_20181208.json',\n",
       " 'twitter_20181209.json',\n",
       " 'twitter_20181210.json',\n",
       " 'twitter_20181211.json',\n",
       " 'twitter_20181212.json',\n",
       " 'twitter_20181213.json',\n",
       " 'twitter_20181214.json',\n",
       " 'twitter_20181215.json',\n",
       " 'twitter_20181216.json',\n",
       " 'twitter_20181217.json',\n",
       " 'twitter_20181218.json',\n",
       " 'twitter_20181219.json',\n",
       " 'twitter_20181220.json',\n",
       " 'twitter_20181221.json',\n",
       " 'twitter_20181222.json',\n",
       " 'twitter_20181223.json',\n",
       " 'twitter_20181224.json',\n",
       " 'twitter_20181225.json',\n",
       " 'twitter_20181226.json',\n",
       " 'twitter_20181227.json',\n",
       " 'twitter_20181228.json',\n",
       " 'twitter_20181229.json',\n",
       " 'twitter_20181230.json',\n",
       " 'twitter_20181231.json',\n",
       " 'twitter_20190101.json',\n",
       " 'twitter_20190102.json',\n",
       " 'twitter_20190103.json',\n",
       " 'twitter_20190104.json',\n",
       " 'twitter_20190105.json',\n",
       " 'twitter_20190106.json',\n",
       " 'twitter_20190107.json',\n",
       " 'twitter_20190108.json',\n",
       " 'twitter_20190109.json',\n",
       " 'twitter_20190110.json',\n",
       " 'twitter_20190111.json',\n",
       " 'twitter_20190112.json',\n",
       " 'twitter_20190113.json',\n",
       " 'twitter_20190114.json',\n",
       " 'twitter_20190115.json',\n",
       " 'twitter_20190116.json',\n",
       " 'twitter_20190117.json',\n",
       " 'twitter_20190118.json',\n",
       " 'twitter_20190119.json',\n",
       " 'twitter_20190120.json',\n",
       " 'twitter_20190121.json',\n",
       " 'twitter_20190122.json',\n",
       " 'twitter_20190123.json',\n",
       " 'twitter_20190124.json',\n",
       " 'twitter_20190125.json',\n",
       " 'twitter_20190126.json',\n",
       " 'twitter_20190127.json',\n",
       " 'twitter_20190128.json',\n",
       " 'twitter_20190129.json',\n",
       " 'twitter_20190130.json',\n",
       " 'twitter_20190131.json',\n",
       " 'twitter_20190201.json',\n",
       " 'twitter_20190202.json',\n",
       " 'twitter_20190203.json',\n",
       " 'twitter_20190204.json',\n",
       " 'twitter_20190205.json',\n",
       " 'twitter_20190206.json',\n",
       " 'twitter_20190207.json',\n",
       " 'twitter_20190208.json',\n",
       " 'twitter_20190209.json',\n",
       " 'twitter_20190210.json',\n",
       " 'twitter_20190211.json',\n",
       " 'twitter_20190212.json',\n",
       " 'twitter_20190213.json',\n",
       " 'twitter_20190214.json',\n",
       " 'twitter_20190215.json',\n",
       " 'twitter_20190216.json',\n",
       " 'twitter_20190217.json',\n",
       " 'twitter_20190218.json',\n",
       " 'twitter_20190219.json',\n",
       " 'twitter_20190220.json',\n",
       " 'twitter_20190221.json',\n",
       " 'twitter_20190222.json',\n",
       " 'twitter_20190223.json',\n",
       " 'twitter_20190224.json',\n",
       " 'twitter_20190225.json',\n",
       " 'twitter_20190226.json',\n",
       " 'twitter_20190227.json',\n",
       " 'twitter_20190228.json',\n",
       " 'twitter_20190301.json',\n",
       " 'twitter_20190302.json',\n",
       " 'twitter_20190303.json',\n",
       " 'twitter_20190304.json',\n",
       " 'twitter_20190305.json',\n",
       " 'twitter_20190306.json',\n",
       " 'twitter_20190307.json',\n",
       " 'twitter_20190308.json',\n",
       " 'twitter_20190309.json',\n",
       " 'twitter_20190310.json',\n",
       " 'twitter_20190311.json',\n",
       " 'twitter_20190312.json',\n",
       " 'twitter_20190313.json',\n",
       " 'twitter_20190314.json',\n",
       " 'twitter_20190315.json',\n",
       " 'twitter_20190316.json',\n",
       " 'twitter_20190317.json',\n",
       " 'twitter_20190318.json',\n",
       " 'twitter_20190319.json',\n",
       " 'twitter_20190320.json',\n",
       " 'twitter_20190321.json',\n",
       " 'twitter_20190322.json',\n",
       " 'twitter_20190323.json',\n",
       " 'twitter_20190324.json',\n",
       " 'twitter_20190325.json',\n",
       " 'twitter_20190326.json',\n",
       " 'twitter_20190327.json',\n",
       " 'twitter_20190328.json',\n",
       " 'twitter_20190329.json',\n",
       " 'twitter_20190330.json',\n",
       " 'twitter_20190331.json',\n",
       " 'twitter_20190401.json',\n",
       " 'twitter_20190402.json',\n",
       " 'twitter_20190403.json',\n",
       " 'twitter_20190404.json',\n",
       " 'twitter_20190405.json',\n",
       " 'twitter_20190406.json',\n",
       " 'twitter_20190407.json',\n",
       " 'twitter_20190408.json',\n",
       " 'twitter_20190409.json',\n",
       " 'twitter_20190410.json',\n",
       " 'twitter_20190411.json',\n",
       " 'twitter_20190412.json',\n",
       " 'twitter_20190413.json',\n",
       " 'twitter_20190414.json',\n",
       " 'twitter_20190415.json',\n",
       " 'twitter_20190416.json',\n",
       " 'twitter_20190417.json',\n",
       " 'twitter_20190418.json',\n",
       " 'twitter_20190419.json',\n",
       " 'twitter_20190420.json',\n",
       " 'twitter_20190421.json',\n",
       " 'twitter_20190422.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames.index('twitter_20180706.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type clicked time  ex.2019031220190312\n"
     ]
    }
   ],
   "source": [
    "given_time = input('type clicked time  ex.20190312')\n",
    "\n",
    "\n",
    "search_range = []\n",
    "\n",
    "for i in range(7):\n",
    "    pointed = 'twitter_{0}.json'.format(given_time)\n",
    "    search_range.append(filenames[filenames.index(pointed)-i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitter_20190312.json',\n",
       " 'twitter_20190311.json',\n",
       " 'twitter_20190310.json',\n",
       " 'twitter_20190309.json',\n",
       " 'twitter_20190308.json',\n",
       " 'twitter_20190307.json',\n",
       " 'twitter_20190306.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:06<00:00,  9.48s/it]\n"
     ]
    }
   ],
   "source": [
    "merged =[]\n",
    "\n",
    "for k in tqdm(search_range):\n",
    "    with open('/home/minkh/Downloads/twitter/{0}'.format(k), encoding='utf-8-sig') as data_file:\n",
    "        for line in data_file:\n",
    "            try:\n",
    "                j = line.split('|')[-1]\n",
    "                merged.append(json.loads(j))\n",
    "            except ValueError:\n",
    "                # You probably have bad JSON\n",
    "                continue\n",
    "\n",
    "# list to dataframe\n",
    "df = pd.DataFrame(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [], 'hashtags': [{'indices': [35, 39]...</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/mq...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121208771604486</td>\n",
       "      <td>1105121208771604486</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2123</td>\n",
       "      <td>False</td>\n",
       "      <td>{'extended_entities': {'media': [{'display_url...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @mayrabbitprince: 190311 마시타 퇴근 #박지훈 #지훈\\n\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 56, 'pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [], 'hashtags': [{'indices': [44, 48]...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121207752511488</td>\n",
       "      <td>1105121207752511488</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7500</td>\n",
       "      <td>False</td>\n",
       "      <td>{'metadata': {'result_type': 'recent', 'iso_la...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @M2MPD: &amp;lt;찾았다 스트레이 키즈&amp;gt; PHOTO TEASER #아...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 198, 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [], 'hashtags': [], 'user_mentions': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121207735660545</td>\n",
       "      <td>1105121207735660545</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>403</td>\n",
       "      <td>False</td>\n",
       "      <td>{'metadata': {'result_type': 'recent', 'iso_la...</td>\n",
       "      <td>&lt;a href=\"https://about.twitter.com/products/tw...</td>\n",
       "      <td>RT @hanna_3542: 로맨스는 별책부록 1화에서 이나영이 여기저기 면접 보고...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 133, 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [{'display_url': 'mediatoday.co.kr/?m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121207366512641</td>\n",
       "      <td>1105121207366512641</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>저널리즘토크쇼J가 저격한 조선.동아일보의 친일 행적 https://t.co/0A9x...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 154, 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [], 'hashtags': [], 'user_mentions': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121206871646208</td>\n",
       "      <td>1105121206871646208</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>@vmstck 저어는 계속 ios를 썼어서...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 85, 'pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  contributors coordinates                      created_at  \\\n",
       "0         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "1         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "2         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "3         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "4         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'urls': [], 'hashtags': [{'indices': [35, 39]...   \n",
       "1  {'urls': [], 'hashtags': [{'indices': [44, 48]...   \n",
       "2  {'urls': [], 'hashtags': [], 'user_mentions': ...   \n",
       "3  {'urls': [{'display_url': 'mediatoday.co.kr/?m...   \n",
       "4  {'urls': [], 'hashtags': [], 'user_mentions': ...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'display_url': 'pic.twitter.com/mq...               0   \n",
       "1                                                NaN               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "   favorited   geo                   id               id_str  ...  \\\n",
       "0      False  None  1105121208771604486  1105121208771604486  ...   \n",
       "1      False  None  1105121207752511488  1105121207752511488  ...   \n",
       "2      False  None  1105121207735660545  1105121207735660545  ...   \n",
       "3      False  None  1105121207366512641  1105121207366512641  ...   \n",
       "4      False  None  1105121206871646208  1105121206871646208  ...   \n",
       "\n",
       "  quoted_status  quoted_status_id quoted_status_id_str  retweet_count  \\\n",
       "0           NaN               NaN                  NaN           2123   \n",
       "1           NaN               NaN                  NaN           7500   \n",
       "2           NaN               NaN                  NaN            403   \n",
       "3           NaN               NaN                  NaN              0   \n",
       "4           NaN               NaN                  NaN              0   \n",
       "\n",
       "  retweeted                                   retweeted_status  \\\n",
       "0     False  {'extended_entities': {'media': [{'display_url...   \n",
       "1     False  {'metadata': {'result_type': 'recent', 'iso_la...   \n",
       "2     False  {'metadata': {'result_type': 'recent', 'iso_la...   \n",
       "3     False                                                NaN   \n",
       "4     False                                                NaN   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"https://about.twitter.com/products/tw...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text truncated  \\\n",
       "0  RT @mayrabbitprince: 190311 마시타 퇴근 #박지훈 #지훈\\n\\...     False   \n",
       "1  RT @M2MPD: &lt;찾았다 스트레이 키즈&gt; PHOTO TEASER #아...     False   \n",
       "2  RT @hanna_3542: 로맨스는 별책부록 1화에서 이나영이 여기저기 면접 보고...     False   \n",
       "3  저널리즘토크쇼J가 저격한 조선.동아일보의 친일 행적 https://t.co/0A9x...     False   \n",
       "4                         @vmstck 저어는 계속 ios를 썼어서...     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'utc_offset': None, 'friends_count': 56, 'pro...  \n",
       "1  {'utc_offset': None, 'friends_count': 198, 'pr...  \n",
       "2  {'utc_offset': None, 'friends_count': 133, 'pr...  \n",
       "3  {'utc_offset': None, 'friends_count': 154, 'pr...  \n",
       "4  {'utc_offset': None, 'friends_count': 85, 'pro...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480377"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['created_at','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date reformatting\n",
    "month = {'Jan': '01', 'Feb': '02', 'Mar': '03','Apr': '04','May': '05','Jun': '06','Jul': '07','Aug': '08', 'Sep': '09','Oct': '10','Nov': '11','Dec': '12'}\n",
    "time_format = [5,1,2,3,4,0]\n",
    "\n",
    "\n",
    "timelist = []\n",
    "for i in range(len(data)):\n",
    "    timelist.append(data['created_at'][i])\n",
    "    \n",
    "def time_reformulate(ori_list, order):\n",
    "    temp = [0]*len(ori_list)\n",
    "    temp = [ori_list[x] for x in order]\n",
    "    temp[1] = month[temp[1]]\n",
    "    time = '. '.join(temp[:4])\n",
    "    return time\n",
    "\n",
    "for i in range(len(timelist)):\n",
    "    timelist[i] = time_reformulate(timelist[i].split(),time_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to list\n",
    "text = []\n",
    "for i in range(len(data)):\n",
    "    text.append(data['text'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  list --> [time, text]\n",
    "\n",
    "data = []\n",
    "for i in range(len(timelist)):\n",
    "    data.append([timelist[i], text[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaner\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub('[a-zA-Z]', '', text)\n",
    "    cleaned_text = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]', '', cleaned_text)\n",
    "    cleaned_text = re.sub('\\n', '', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i][1] = clean_text(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for i in range(len(data)):\n",
    "    tweets.append(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480377/480377 [1:05:12<00:00, 122.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for tweet in tqdm(tweets):\n",
    "    tweets[tweets.index(tweet)] = okt.nouns(tweet)\n",
    "    #sents[sents.index(i)] = komoran.nouns(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/480377 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "java.lang.NullPointerExceptionPyRaisable",
     "evalue": "java.lang.NullPointerException",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mjava.lang.NullPointerExceptionPyRaisable\u001b[0m  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e918daa3ce68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_kmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#tweets[tweets.index(tweet)] = okt.nouns(tweet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtweets_kmr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweets_kmr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkomoran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnouns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mkh3/lib/python3.7/site-packages/konlpy/tag/_komoran.py\u001b[0m in \u001b[0;36mnouns\u001b[0;34m(self, phrase)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\"Noun extractor.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mtagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagged\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mkh3/lib/python3.7/site-packages/konlpy/tag/_komoran.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjki\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTokenList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMorph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mjava.lang.NullPointerExceptionPyRaisable\u001b[0m: java.lang.NullPointerException"
     ]
    }
   ],
   "source": [
    "tweets_kmr = []\n",
    "for i in range(len(data)):\n",
    "    tweets_kmr.append(data[i][1])\n",
    "\n",
    "for tweet in tqdm(tweets_kmr):\n",
    "    #tweets[tweets.index(tweet)] = okt.nouns(tweet)\n",
    "    tweets_kmr[tweets_kmr.index(tweet)] = komoran.nouns(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(timelist)):\n",
    "    data.append([timelist[i], text[i], tweets[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키워드를 입력하세요: 부동산\n"
     ]
    }
   ],
   "source": [
    "# keyword 입력받고\n",
    "# tweet 들 중에 해당 키워드가 있으면\n",
    "# 어떤 키워드들이 많이 나오는지~\n",
    "\n",
    "keyword = input(\"키워드를 입력하세요: \") # 첫페이지에서 사용자가 입력한 것\n",
    "#timestamp = '사용자가 클릭한 시점' # 넘겨받아와서~\n",
    "\n",
    "# tweet load 해당 날짜. \n",
    "\n",
    "# 화면상 원하는 시점대를 클릭하면 그 시점에서의 트윗들 분석.\n",
    "# 그 시점이라 하고. 그 시점 포함 전후로(500개 트윗 or 며칠(없을수도..)) 트윗 //뉴스?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_nouns = []\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i][2])):\n",
    "        bag_nouns.append(data[i][2][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5888975"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_nouns = list(set(bag_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69218"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_cnt = dict.fromkeys(bag_nouns,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(data)):\n",
    "    if keyword in data[i][2]:\n",
    "        for noun in data[i][2]:\n",
    "            noun_cnt[noun] = noun_cnt[noun] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    " \n",
    "related_keywords = sorted(noun_cnt.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('부동산', 150),\n",
       " ('위조', 80),\n",
       " ('통장', 36),\n",
       " ('거래', 34),\n",
       " ('증', 32),\n",
       " ('탓', 27),\n",
       " ('떼', 21),\n",
       " ('모두', 21),\n",
       " ('자기', 21),\n",
       " ('국민', 21),\n",
       " ('뭐', 20),\n",
       " ('놈', 20),\n",
       " ('사리', 20),\n",
       " ('명', 20),\n",
       " ('외교', 20),\n",
       " ('임금', 20),\n",
       " ('압', 20),\n",
       " ('대통령', 20),\n",
       " ('및', 20),\n",
       " ('공조', 20),\n",
       " ('자그마치', 20),\n",
       " ('정부', 20),\n",
       " ('사욕', 20),\n",
       " ('트리', 20),\n",
       " ('개새끼', 20),\n",
       " ('인터폴', 20),\n",
       " ('순간', 20),\n",
       " ('무너', 20),\n",
       " ('아파트', 19),\n",
       " ('투자', 18),\n",
       " ('집값', 17),\n",
       " ('돈', 16),\n",
       " ('증명서', 16),\n",
       " ('제작', 16),\n",
       " ('작년', 16),\n",
       " ('투기', 14),\n",
       " ('매매', 12),\n",
       " ('확인', 11),\n",
       " ('것', 11),\n",
       " ('착취', 11),\n",
       " ('생각', 11),\n",
       " ('나라', 11),\n",
       " ('바로', 10),\n",
       " ('거품', 10),\n",
       " ('국토', 10),\n",
       " ('불로소득', 10),\n",
       " ('집', 10),\n",
       " ('투', 9),\n",
       " ('악마', 9),\n",
       " ('언론사', 9),\n",
       " ('이', 9),\n",
       " ('상담', 9),\n",
       " ('언론', 9),\n",
       " ('질', 9),\n",
       " ('조합', 9),\n",
       " ('호황', 9),\n",
       " ('일본', 9),\n",
       " ('동탄', 9),\n",
       " ('문제', 9),\n",
       " ('빼기', 9),\n",
       " ('카톡', 9),\n",
       " ('선동', 9),\n",
       " ('원인', 9),\n",
       " ('잔고', 8),\n",
       " ('예금', 8),\n",
       " ('강사', 8),\n",
       " ('입출금', 8),\n",
       " ('입금', 8),\n",
       " ('역위', 8),\n",
       " ('외환', 8),\n",
       " ('논리', 8),\n",
       " ('통지서', 8),\n",
       " ('역서', 8),\n",
       " ('실적', 8),\n",
       " ('여권', 8),\n",
       " ('잔액', 8),\n",
       " ('송금', 8),\n",
       " ('계약서', 8),\n",
       " ('말', 8),\n",
       " ('선점', 7),\n",
       " ('축척', 7),\n",
       " ('중', 7),\n",
       " ('그대로', 7),\n",
       " ('제도', 7),\n",
       " ('중국', 7),\n",
       " ('토지', 7),\n",
       " ('이유', 7),\n",
       " ('재벌', 7),\n",
       " ('흡혈귀', 7),\n",
       " ('총', 7),\n",
       " ('소득', 7),\n",
       " ('대해', 7),\n",
       " ('보', 6),\n",
       " ('자식', 6),\n",
       " ('량', 6),\n",
       " ('건수', 6),\n",
       " ('왜', 6),\n",
       " ('그', 6),\n",
       " ('가격', 6),\n",
       " ('때', 6),\n",
       " ('경제', 6),\n",
       " ('임', 6),\n",
       " ('수', 6),\n",
       " ('더', 6),\n",
       " ('계약', 6),\n",
       " ('내', 6),\n",
       " ('종합', 6),\n",
       " ('전월세', 6),\n",
       " ('자', 5),\n",
       " ('대한민국', 5),\n",
       " ('임대', 5),\n",
       " ('지역', 5),\n",
       " ('건물', 5),\n",
       " ('김장섭', 5),\n",
       " ('시장', 5),\n",
       " ('세', 5),\n",
       " ('폭등', 5),\n",
       " ('의도', 5),\n",
       " ('비리', 5),\n",
       " ('앞', 5),\n",
       " ('의', 5),\n",
       " ('행위', 4),\n",
       " ('세제', 4),\n",
       " ('사교육비', 4),\n",
       " ('산업', 4),\n",
       " ('유세', 4),\n",
       " ('업자', 4),\n",
       " ('등', 4),\n",
       " ('엄마', 4),\n",
       " ('나경원', 4),\n",
       " ('후', 4),\n",
       " ('모든', 4),\n",
       " ('낫다', 4),\n",
       " ('참여정부', 4),\n",
       " ('게', 4),\n",
       " ('간', 4),\n",
       " ('혜택', 4),\n",
       " ('저런', 4),\n",
       " ('애', 4),\n",
       " ('재테크', 4),\n",
       " ('공부', 4),\n",
       " ('실거', 4),\n",
       " ('접', 4),\n",
       " ('관련', 4),\n",
       " ('치', 4),\n",
       " ('재건축', 4),\n",
       " ('사건', 4),\n",
       " ('반대', 4),\n",
       " ('거주', 4),\n",
       " ('성장', 4),\n",
       " ('첫', 4),\n",
       " ('광주', 4),\n",
       " ('광역시', 4),\n",
       " ('리츠', 4),\n",
       " ('비', 4),\n",
       " ('달리', 4),\n",
       " ('폭행', 4),\n",
       " ('일가', 4),\n",
       " ('감금', 4),\n",
       " ('국가', 4),\n",
       " ('결말', 4),\n",
       " ('부산광역시', 4),\n",
       " ('전원책', 4),\n",
       " ('주택', 4),\n",
       " ('연봉', 4),\n",
       " ('류', 4),\n",
       " ('방씨', 4),\n",
       " ('실', 4),\n",
       " ('상승', 4),\n",
       " ('분업', 3),\n",
       " ('규모', 3),\n",
       " ('세력', 3),\n",
       " ('센터', 3),\n",
       " ('공급', 3),\n",
       " ('블록', 3),\n",
       " ('당시', 3),\n",
       " ('블로그', 3),\n",
       " ('농단', 3),\n",
       " ('진행', 3),\n",
       " ('국토교통부', 3),\n",
       " ('이익', 3),\n",
       " ('체계', 3),\n",
       " ('비법', 3),\n",
       " ('일', 3),\n",
       " ('공시가격', 3),\n",
       " ('체인', 3),\n",
       " ('매물', 3),\n",
       " ('부채', 3),\n",
       " ('자금', 3),\n",
       " ('신도시', 3),\n",
       " ('지식', 3),\n",
       " ('법', 3),\n",
       " ('서민', 3),\n",
       " ('공유', 3),\n",
       " ('금리', 3),\n",
       " ('점포', 3),\n",
       " ('출처', 3),\n",
       " ('다운', 3),\n",
       " ('수익', 3),\n",
       " ('공장', 3),\n",
       " ('수입', 3),\n",
       " ('급속', 3),\n",
       " ('임금노동', 3),\n",
       " ('스위스', 3),\n",
       " ('오히려', 3),\n",
       " ('한국', 3),\n",
       " ('달러', 3),\n",
       " ('그냥', 2),\n",
       " ('딸', 2),\n",
       " ('단속', 2),\n",
       " ('타당', 2),\n",
       " ('경매', 2),\n",
       " ('조사', 2),\n",
       " ('영업', 2),\n",
       " ('경찰', 2),\n",
       " ('가능성', 2),\n",
       " ('일찍', 2),\n",
       " ('담보', 2),\n",
       " ('양보', 2),\n",
       " ('경기', 2),\n",
       " ('도입', 2),\n",
       " ('관리', 2),\n",
       " ('보기', 2),\n",
       " ('구매', 2),\n",
       " ('이자', 2),\n",
       " ('충청남도', 2),\n",
       " ('수협', 2),\n",
       " ('공동', 2),\n",
       " ('스마트폰', 2),\n",
       " ('오픈', 2),\n",
       " ('박근혜', 2),\n",
       " ('자전거', 2),\n",
       " ('불', 2),\n",
       " ('관심', 2),\n",
       " ('망언', 2),\n",
       " ('종부세', 2),\n",
       " ('대출', 2),\n",
       " ('집중', 2),\n",
       " ('하락', 2),\n",
       " ('정신', 2),\n",
       " ('가야', 2),\n",
       " ('개념', 2),\n",
       " ('개', 2),\n",
       " ('핵보유국', 2),\n",
       " ('채', 2),\n",
       " ('과정', 2),\n",
       " ('금융', 2),\n",
       " ('노동', 2),\n",
       " ('국세청', 2),\n",
       " ('전면', 2),\n",
       " ('수요', 2),\n",
       " ('인근', 2),\n",
       " ('국회', 2),\n",
       " ('님', 2),\n",
       " ('테라', 2),\n",
       " ('높이', 2),\n",
       " ('분배', 2),\n",
       " ('정지영', 2),\n",
       " ('경산시', 2),\n",
       " ('절반', 2),\n",
       " ('우리', 2),\n",
       " ('값', 2),\n",
       " ('리', 2),\n",
       " ('해피', 2),\n",
       " ('벤츠', 2),\n",
       " ('효녀', 2),\n",
       " ('답장', 2),\n",
       " ('이명', 2),\n",
       " ('사장', 2),\n",
       " ('안정', 2),\n",
       " ('의원', 2),\n",
       " ('정권', 2),\n",
       " ('고가', 2),\n",
       " ('해외', 2),\n",
       " ('조금', 2),\n",
       " ('축소', 2),\n",
       " ('남', 2),\n",
       " ('단독주택', 2),\n",
       " ('소액', 2),\n",
       " ('통해', 2),\n",
       " ('요', 2),\n",
       " ('특혜', 2),\n",
       " ('공화국', 2),\n",
       " ('지구', 2),\n",
       " ('욕심', 2),\n",
       " ('국정', 2),\n",
       " ('정보', 2),\n",
       " ('땅', 2),\n",
       " ('한당', 2),\n",
       " ('층', 2),\n",
       " ('가지', 2),\n",
       " ('버블', 2),\n",
       " ('위기', 2),\n",
       " ('타워', 2),\n",
       " ('분', 2),\n",
       " ('퍼스트', 2),\n",
       " ('정답', 2),\n",
       " ('하루', 2),\n",
       " ('정책', 2),\n",
       " ('자산', 2),\n",
       " ('개인', 2),\n",
       " ('언제', 2),\n",
       " ('소유', 2),\n",
       " ('민통선', 2),\n",
       " ('불법', 2),\n",
       " ('홍대', 2),\n",
       " ('중개', 2),\n",
       " ('구축', 2),\n",
       " ('주식시장', 2),\n",
       " ('조사해', 2),\n",
       " ('차', 2),\n",
       " ('개발', 2),\n",
       " ('위해', 2),\n",
       " ('굴복', 2),\n",
       " ('충청북도', 2),\n",
       " ('여러분', 2),\n",
       " ('아르바이트', 2),\n",
       " ('마디', 1),\n",
       " ('과잉', 1),\n",
       " ('샐러리맨', 1),\n",
       " ('자체', 1),\n",
       " ('만큼', 1),\n",
       " ('박사', 1),\n",
       " ('견우직녀', 1),\n",
       " ('법인', 1),\n",
       " ('김정민', 1),\n",
       " ('자본가', 1),\n",
       " ('싹', 1),\n",
       " ('눈', 1),\n",
       " ('매', 1),\n",
       " ('이전', 1),\n",
       " ('고정관념', 1),\n",
       " ('이름', 1),\n",
       " ('모자', 1),\n",
       " ('화제', 1),\n",
       " ('완료', 1),\n",
       " ('구청', 1),\n",
       " ('며', 1),\n",
       " ('이상규', 1),\n",
       " ('석사동', 1),\n",
       " ('링깃', 1),\n",
       " ('문학', 1),\n",
       " ('둘', 1),\n",
       " ('상가', 1),\n",
       " ('폭락', 1),\n",
       " ('미국', 1),\n",
       " ('존버', 1),\n",
       " ('방법', 1),\n",
       " ('준비', 1),\n",
       " ('계단', 1),\n",
       " ('인구', 1),\n",
       " ('제조업', 1),\n",
       " ('도모', 1),\n",
       " ('이해', 1),\n",
       " ('다양', 1),\n",
       " ('동영상', 1),\n",
       " ('곡', 1),\n",
       " ('비교', 1),\n",
       " ('상이', 1),\n",
       " ('지난', 1),\n",
       " ('삐끼', 1),\n",
       " ('적', 1),\n",
       " ('환수', 1),\n",
       " ('교대', 1),\n",
       " ('기축통화', 1),\n",
       " ('첫째', 1),\n",
       " ('아무나', 1),\n",
       " ('신발', 1),\n",
       " ('지방', 1),\n",
       " ('절감', 1),\n",
       " ('우선', 1),\n",
       " ('터', 1),\n",
       " ('영국', 1),\n",
       " ('비아그라', 1),\n",
       " ('사회', 1),\n",
       " ('적발', 1),\n",
       " ('즉', 1),\n",
       " ('권세', 1),\n",
       " ('세도', 1),\n",
       " ('나', 1),\n",
       " ('함', 1),\n",
       " ('장판', 1),\n",
       " ('더욱', 1),\n",
       " ('낮', 1),\n",
       " ('체제', 1),\n",
       " ('헤', 1),\n",
       " ('무역', 1),\n",
       " ('는걸', 1),\n",
       " ('사람', 1),\n",
       " ('차이나', 1),\n",
       " ('유치원', 1),\n",
       " ('낙찰', 1),\n",
       " ('돈옷', 1),\n",
       " ('정상화', 1),\n",
       " ('를', 1),\n",
       " ('새벽', 1),\n",
       " ('사무실', 1),\n",
       " ('마적', 1),\n",
       " ('사설', 1),\n",
       " ('밸리', 1),\n",
       " ('세금', 1),\n",
       " ('양치질', 1),\n",
       " ('매입', 1),\n",
       " ('보유', 1),\n",
       " ('공산품', 1),\n",
       " ('카페', 1),\n",
       " ('고발', 1),\n",
       " ('율', 1),\n",
       " ('이정', 1),\n",
       " ('강남스타일', 1),\n",
       " ('면제', 1),\n",
       " ('스포츠', 1),\n",
       " ('국토부', 1),\n",
       " ('브레이크뉴스', 1),\n",
       " ('재', 1),\n",
       " ('사업', 1),\n",
       " ('번호', 1),\n",
       " ('노원구', 1),\n",
       " ('무조건', 1),\n",
       " ('수사', 1),\n",
       " ('민주주의', 1),\n",
       " ('다음', 1),\n",
       " ('쓰레기', 1),\n",
       " ('성사', 1),\n",
       " ('누군가', 1),\n",
       " ('대량', 1),\n",
       " ('조정', 1),\n",
       " ('하', 1),\n",
       " ('둘째', 1),\n",
       " ('버풀', 1),\n",
       " ('파괴', 1),\n",
       " ('젠', 1),\n",
       " ('정상회담', 1),\n",
       " ('비누', 1),\n",
       " ('깨', 1),\n",
       " ('포함', 1),\n",
       " ('관람', 1),\n",
       " ('연락', 1),\n",
       " ('썰쩐', 1),\n",
       " ('코리아', 1),\n",
       " ('용가리', 1),\n",
       " ('열풍', 1),\n",
       " ('라면', 1),\n",
       " ('노력', 1),\n",
       " ('통채', 1),\n",
       " ('인위', 1),\n",
       " ('감상', 1),\n",
       " ('오피스텔', 1),\n",
       " ('피아노', 1),\n",
       " ('브라질', 1),\n",
       " ('희소', 1),\n",
       " ('한창', 1),\n",
       " ('심지어', 1),\n",
       " ('자본', 1),\n",
       " ('기본소득', 1),\n",
       " ('쥐', 1),\n",
       " ('오피', 1),\n",
       " ('역', 1),\n",
       " ('곳', 1),\n",
       " ('정도', 1),\n",
       " ('최고', 1),\n",
       " ('상품', 1),\n",
       " ('끝', 1),\n",
       " ('전문가', 1),\n",
       " ('전액', 1),\n",
       " ('수산시장', 1),\n",
       " ('미세먼지', 1),\n",
       " ('주인', 1),\n",
       " ('빌라', 1),\n",
       " ('질문', 1),\n",
       " ('부모', 1),\n",
       " ('처음', 1),\n",
       " ('트윈스', 1),\n",
       " ('위', 1),\n",
       " ('블랙리스트', 1),\n",
       " ('절대', 1),\n",
       " ('통과', 1),\n",
       " ('택시', 1),\n",
       " ('영화음악', 1),\n",
       " ('부정선거', 1),\n",
       " ('노량진', 1),\n",
       " ('발악', 1),\n",
       " ('서로', 1),\n",
       " ('전혀', 1),\n",
       " ('민간인사찰', 1),\n",
       " ('예술', 1),\n",
       " ('집단', 1),\n",
       " ('외', 1),\n",
       " ('가정', 1),\n",
       " ('환율', 1),\n",
       " ('정치', 1),\n",
       " ('기사', 1),\n",
       " ('스칸다', 1),\n",
       " ('업', 1),\n",
       " ('캡', 1),\n",
       " ('세수', 1),\n",
       " ('왕국', 1),\n",
       " ('듯', 1),\n",
       " ('주민등록', 1),\n",
       " ('북', 1),\n",
       " ('초과', 1),\n",
       " ('테크노', 1),\n",
       " ('거대', 1),\n",
       " ('노골', 1),\n",
       " ('요구', 1),\n",
       " ('엘지', 1),\n",
       " ('불황', 1),\n",
       " ('철', 1),\n",
       " ('화장품', 1),\n",
       " ('관여', 1),\n",
       " ('심사', 1),\n",
       " ('악세사리', 1),\n",
       " ('젊은이', 1),\n",
       " ('돌려막기', 1),\n",
       " ('주장', 1),\n",
       " ('평형', 1),\n",
       " ('주가', 1),\n",
       " ('물건', 1),\n",
       " ('취약', 1),\n",
       " ('해당', 1),\n",
       " ('널리', 1),\n",
       " ('디즈니', 1),\n",
       " ('순위', 1),\n",
       " ('대학생', 1),\n",
       " ('금융위기', 1),\n",
       " ('빚', 1),\n",
       " ('전국', 1),\n",
       " ('안해', 1),\n",
       " ('바', 1),\n",
       " ('왕족', 1),\n",
       " ('취미', 1),\n",
       " ('속옷', 1),\n",
       " ('미투', 1),\n",
       " ('연주', 1),\n",
       " ('폭탄', 1),\n",
       " ('한마디', 1),\n",
       " ('동시', 1),\n",
       " ('발상', 1),\n",
       " ('장갑', 1),\n",
       " ('상숭', 1),\n",
       " ('쉬', 1),\n",
       " ('유지', 1),\n",
       " ('푸트', 1),\n",
       " ('여왕', 1),\n",
       " ('뿐', 1),\n",
       " ('못', 1),\n",
       " ('관', 1),\n",
       " ('석사', 1),\n",
       " ('절벽', 1),\n",
       " ('이하', 1),\n",
       " ('손', 1),\n",
       " ('일어나지', 1),\n",
       " ('장유동', 1),\n",
       " ('투입', 1),\n",
       " ('시세', 1),\n",
       " ('노년', 1),\n",
       " ('전쟁', 1),\n",
       " ('카드', 1),\n",
       " ('주체', 1),\n",
       " ('매기', 1),\n",
       " ('파산', 1),\n",
       " ('오피스', 1),\n",
       " ('률', 1),\n",
       " ('영토', 1),\n",
       " ('영역', 1),\n",
       " ('인건비', 1),\n",
       " ('세계', 1),\n",
       " ('바스', 1),\n",
       " ('최저임금', 1),\n",
       " ('노후', 1),\n",
       " ('통뼈', 1),\n",
       " ('날', 1),\n",
       " ('알리', 1),\n",
       " ('편입', 1),\n",
       " ('동산', 1),\n",
       " ('대선', 1),\n",
       " ('때문', 1),\n",
       " ('보이', 1),\n",
       " ('이재명', 1),\n",
       " ('관성', 1),\n",
       " ('지금', 1),\n",
       " ('포', 1),\n",
       " ('원', 1),\n",
       " ('단순', 1),\n",
       " ('시간', 1),\n",
       " ('실시', 1),\n",
       " ('서적', 1),\n",
       " ('부동산경매', 1),\n",
       " ('급매', 1),\n",
       " ('선거', 1),\n",
       " ('홀릭', 1),\n",
       " ('당', 1),\n",
       " ('화장지', 1),\n",
       " ('기레기', 1),\n",
       " ('밤', 1),\n",
       " ('부분', 1),\n",
       " ('해도', 1),\n",
       " ('절하', 1),\n",
       " ('재산', 1),\n",
       " ('호객', 1),\n",
       " ('발', 1),\n",
       " ('직성', 1),\n",
       " ('오늘', 1),\n",
       " ('상당', 1),\n",
       " ('장님', 1),\n",
       " ('강시', 1),\n",
       " ('저항', 1),\n",
       " ('바르셀로나', 1),\n",
       " ('침범', 1),\n",
       " ('서류', 1),\n",
       " ('저걸', 1),\n",
       " ('마련', 1),\n",
       " ('다이소', 1),\n",
       " ('대면', 1),\n",
       " ('여기', 1),\n",
       " ('목욕', 1),\n",
       " ('최', 1),\n",
       " ('가구', 1),\n",
       " ('붕괴', 1),\n",
       " ('켓', 1),\n",
       " ('의존', 1),\n",
       " ('직장', 1),\n",
       " ('좀', 1),\n",
       " ('보고', 1),\n",
       " ('추리', 1),\n",
       " ('음매', 1),\n",
       " ('극좌', 1),\n",
       " ('파주', 1),\n",
       " ('디자인', 1),\n",
       " ('추진', 1),\n",
       " ('커피', 1),\n",
       " ('권력', 1),\n",
       " ('도배', 1),\n",
       " ('저출산', 1),\n",
       " ('호구', 1),\n",
       " ('집차땅', 1),\n",
       " ('양적완화', 1),\n",
       " ('제화', 1),\n",
       " ('현실', 1),\n",
       " ('토', 1),\n",
       " ('두건', 1),\n",
       " ('학교', 1),\n",
       " ('양현석', 1),\n",
       " ('이면', 1),\n",
       " ('아지', 1),\n",
       " ('연구원', 1),\n",
       " ('고정', 1),\n",
       " ('경실련', 1),\n",
       " ('춘천시', 1),\n",
       " ('힐링캠프', 1),\n",
       " ('충족', 1),\n",
       " ('취직', 1),\n",
       " ('인상', 1),\n",
       " ('소유자', 1),\n",
       " ('강석', 1),\n",
       " ('무장', 1),\n",
       " ('교란', 1),\n",
       " ('사서', 1),\n",
       " ('경이', 1),\n",
       " ('행정처분', 1),\n",
       " ('살', 1),\n",
       " ('문산', 1),\n",
       " ('불합리', 1),\n",
       " ('청년', 1),\n",
       " ('모델링', 1),\n",
       " ('상황', 1),\n",
       " ('왜봐', 1),\n",
       " ('위안화', 1),\n",
       " ('신문', 1),\n",
       " ('통화', 1),\n",
       " ('대거', 1),\n",
       " ('벌레', 1),\n",
       " ('숟가락', 1),\n",
       " ('땅값', 1),\n",
       " ('또', 1),\n",
       " ('양정', 1),\n",
       " ('평균', 1),\n",
       " ('자영', 1),\n",
       " ('산다', 1),\n",
       " ('부부', 1),\n",
       " ('허구', 1),\n",
       " ('임대료', 1),\n",
       " ('정보망', 1),\n",
       " ('자기계발', 1),\n",
       " ('버', 1),\n",
       " ('정평', 1),\n",
       " ('개방', 1),\n",
       " ('볼', 1),\n",
       " ('무슨', 1),\n",
       " ('결혼', 1),\n",
       " ('노래', 1),\n",
       " ('건강', 1),\n",
       " ('구두', 1),\n",
       " ('공공기관', 1),\n",
       " ('설마', 1),\n",
       " ('직전', 1),\n",
       " ('지속', 1),\n",
       " ('임대주택', 1),\n",
       " ('전', 1),\n",
       " ('부자', 1),\n",
       " ('관치', 1),\n",
       " ('전체', 1),\n",
       " ('형태', 1),\n",
       " ('페북', 1),\n",
       " ('효', 1),\n",
       " ('확정', 1),\n",
       " ('직구', 1),\n",
       " ('대기업', 1),\n",
       " ('생애', 1),\n",
       " ('타운', 1),\n",
       " ('기준', 1),\n",
       " ('개입', 1),\n",
       " ('죽', 1),\n",
       " ('부양', 1),\n",
       " ('생산', 1),\n",
       " ('운영', 1),\n",
       " ('제주도', 1),\n",
       " ('틈새', 1),\n",
       " ('업계', 1),\n",
       " ('직업', 1),\n",
       " ('식', 1),\n",
       " ('몰락', 1),\n",
       " ('금융시장', 1),\n",
       " ('시민단체', 1),\n",
       " ('축구', 1),\n",
       " ('대량생산', 1),\n",
       " ('스릴러', 1),\n",
       " ('지랄', 1),\n",
       " ('주거', 1),\n",
       " ('상업', 1),\n",
       " ('사옥', 1),\n",
       " ('월세', 1),\n",
       " ('회원', 1),\n",
       " ('하방', 1),\n",
       " ('용적', 1),\n",
       " ('점유', 1),\n",
       " ('주목', 1),\n",
       " ('그림자', 1),\n",
       " ('번', 1),\n",
       " ('위험', 1),\n",
       " ('반값', 1),\n",
       " ('젓가락', 1),\n",
       " ('민들레', 1),\n",
       " ('파티마', 0),\n",
       " ('어벤져스', 0),\n",
       " ('세꼬시', 0),\n",
       " ('술고래', 0),\n",
       " ('에스엠', 0),\n",
       " ('코미', 0),\n",
       " ('망원렌즈', 0),\n",
       " ('고창', 0),\n",
       " ('맛탕', 0),\n",
       " ('짤렸으', 0),\n",
       " ('그르', 0),\n",
       " ('패션쇼', 0),\n",
       " ('연설', 0),\n",
       " ('율사', 0),\n",
       " ('봉착', 0),\n",
       " ('뒤엠', 0),\n",
       " ('죳대', 0),\n",
       " ('뎸오', 0),\n",
       " ('정의롭다', 0),\n",
       " ('녠', 0),\n",
       " ('컨트롤러', 0),\n",
       " ('이찬', 0),\n",
       " ('충무아트홀', 0),\n",
       " ('때비', 0),\n",
       " ('잡스', 0),\n",
       " ('디딕', 0),\n",
       " ('호기', 0),\n",
       " ('데뷔초', 0),\n",
       " ('광맥', 0),\n",
       " ('다준비해놧다', 0),\n",
       " ('가라사대', 0),\n",
       " ('라르', 0),\n",
       " ('그로', 0),\n",
       " ('화원', 0),\n",
       " ('준쟝', 0),\n",
       " ('돌진', 0),\n",
       " ('조항', 0),\n",
       " ('유권해석', 0),\n",
       " ('혋혦혴혵혳혰혺', 0),\n",
       " ('르시님', 0),\n",
       " ('애뤈', 0),\n",
       " ('헬레', 0),\n",
       " ('교가', 0),\n",
       " ('뉴시스', 0),\n",
       " ('글킨', 0),\n",
       " ('래핑', 0),\n",
       " ('비웃음', 0),\n",
       " ('참여자', 0),\n",
       " ('코숏', 0),\n",
       " ('뇌전증', 0),\n",
       " ('뉴스앤조이', 0),\n",
       " ('플섹무새', 0),\n",
       " ('으엌', 0),\n",
       " ('일상물', 0),\n",
       " ('왘차원', 0),\n",
       " ('심부전증', 0),\n",
       " ('불닭볶음면', 0),\n",
       " ('청탑', 0),\n",
       " ('만천원', 0),\n",
       " ('귀척', 0),\n",
       " ('민경욱', 0),\n",
       " ('타카', 0),\n",
       " ('휴트하쟈너', 0),\n",
       " ('강모', 0),\n",
       " ('헤히히헿히', 0),\n",
       " ('호공', 0),\n",
       " ('셒구', 0),\n",
       " ('양로원', 0),\n",
       " ('쏭진쵸', 0),\n",
       " ('다과', 0),\n",
       " ('퐑퐀퐌', 0),\n",
       " ('악역', 0),\n",
       " ('패치', 0),\n",
       " ('끄윽끄윽', 0),\n",
       " ('피진', 0),\n",
       " ('청자', 0),\n",
       " ('애첩', 0),\n",
       " ('보안', 0),\n",
       " ('명훼감', 0),\n",
       " ('퍽침', 0),\n",
       " ('토이', 0),\n",
       " ('취했음', 0),\n",
       " ('밀하님늦', 0),\n",
       " ('월칸', 0),\n",
       " ('반타작', 0),\n",
       " ('트와이스', 0),\n",
       " ('텔레비전', 0),\n",
       " ('어으으으흑', 0),\n",
       " ('완존이뻐', 0),\n",
       " ('열광', 0),\n",
       " ('맘았', 0),\n",
       " ('양탄자', 0),\n",
       " ('혯', 0),\n",
       " ('무법', 0),\n",
       " ('자바스크립트', 0),\n",
       " ('많', 0),\n",
       " ('호두과자', 0),\n",
       " ('페뇨상', 0),\n",
       " ('차훈', 0),\n",
       " ('커피숍', 0),\n",
       " ('라쟈', 0),\n",
       " ('점박이', 0),\n",
       " ('호스', 0),\n",
       " ('체뭉이', 0),\n",
       " ('케이마쿤', 0),\n",
       " ('렌티큘러비하인드', 0),\n",
       " ('쬬', 0),\n",
       " ('해상자위대', 0),\n",
       " ('비룡', 0),\n",
       " ('머쓱', 0),\n",
       " ('상서', 0),\n",
       " ('카루타', 0),\n",
       " ('줄알', 0),\n",
       " ('두시의데이트', 0),\n",
       " ('뿌듯허네', 0),\n",
       " ('진쨰', 0),\n",
       " ('걸핏하면', 0),\n",
       " ('비스므리', 0),\n",
       " ('소화', 0),\n",
       " ('순창', 0),\n",
       " ('귀축', 0),\n",
       " ('역정', 0),\n",
       " ('멘스', 0),\n",
       " ('슬쏘', 0),\n",
       " ('쌤', 0),\n",
       " ('마감', 0),\n",
       " ('켄트', 0),\n",
       " ('바닝뿌', 0),\n",
       " ('개팀', 0),\n",
       " ('잘자랏', 0),\n",
       " ('젯상', 0),\n",
       " ('쉬방', 0),\n",
       " ('추최', 0),\n",
       " ('남중', 0),\n",
       " ('말파이트', 0),\n",
       " ('된닼', 0),\n",
       " ('야만족', 0),\n",
       " ('슨스', 0),\n",
       " ('정하슈', 0),\n",
       " ('전라북도', 0),\n",
       " ('텔포된다', 0),\n",
       " ('콜라', 0),\n",
       " ('커제', 0),\n",
       " ('보상', 0),\n",
       " ('괜츈합니다', 0),\n",
       " ('무속인', 0),\n",
       " ('배씨', 0),\n",
       " ('플라이트', 0),\n",
       " ('본바탕', 0),\n",
       " ('헤롱헤롱', 0),\n",
       " ('거암', 0),\n",
       " ('남초', 0),\n",
       " ('진찰', 0),\n",
       " ('박규원', 0),\n",
       " ('우련', 0),\n",
       " ('강남구청역', 0),\n",
       " ('후계', 0),\n",
       " ('퓼퓸퓾퓵', 0),\n",
       " ('엄동설한', 0),\n",
       " ('코건좀', 0),\n",
       " ('이원화', 0),\n",
       " ('셰르', 0),\n",
       " ('일제강점기', 0),\n",
       " ('플루토늄', 0),\n",
       " ('순이', 0),\n",
       " ('쩜씩', 0),\n",
       " ('후불', 0),\n",
       " ('다릿심', 0),\n",
       " ('흔헙', 0),\n",
       " ('예산', 0),\n",
       " ('음표', 0),\n",
       " ('상모사곡동', 0),\n",
       " ('어뜩케', 0),\n",
       " ('나카요시', 0),\n",
       " ('클목팟', 0),\n",
       " ('호용', 0),\n",
       " ('타네따릉', 0),\n",
       " ('넷중', 0),\n",
       " ('빡구님', 0),\n",
       " ('견성', 0),\n",
       " ('늼', 0),\n",
       " ('거막', 0),\n",
       " ('맹', 0),\n",
       " ('냉증', 0),\n",
       " ('쿠쿸', 0),\n",
       " ('상반', 0),\n",
       " ('봉사활동', 0),\n",
       " ('홍위병', 0),\n",
       " ('파킹맨', 0),\n",
       " ('넹좋은꿈', 0),\n",
       " ('본의', 0),\n",
       " ('황석희', 0),\n",
       " ('나달', 0),\n",
       " ('홚홧', 0),\n",
       " ('압둘라', 0),\n",
       " ('쌍괴', 0),\n",
       " ('유인원', 0),\n",
       " ('비떱', 0),\n",
       " ('윤비', 0),\n",
       " ('결선', 0),\n",
       " ('언플', 0),\n",
       " ('방향성', 0),\n",
       " ('과로', 0),\n",
       " ('묵념', 0),\n",
       " ('바이퍼', 0),\n",
       " ('생동', 0),\n",
       " ('펜넬', 0),\n",
       " ('그라스', 0),\n",
       " ('뎉', 0),\n",
       " ('엔씨', 0),\n",
       " ('있엇어', 0),\n",
       " ('엑솝', 0),\n",
       " ('현직', 0),\n",
       " ('밴쿠버', 0),\n",
       " ('괴불나무', 0),\n",
       " ('롸', 0),\n",
       " ('통령', 0),\n",
       " ('눌릴', 0),\n",
       " ('레행궈', 0),\n",
       " ('강회', 0),\n",
       " ('에펙레전', 0),\n",
       " ('하절', 0),\n",
       " ('협화', 0),\n",
       " ('썬더', 0),\n",
       " ('마쟈', 0),\n",
       " ('트럿트토', 0),\n",
       " ('트릭스터', 0),\n",
       " ('려워', 0),\n",
       " ('이처', 0),\n",
       " ('미챠써', 0),\n",
       " ('테셀레이션', 0),\n",
       " ('씨쥐', 0),\n",
       " ('해스', 0),\n",
       " ('장담', 0),\n",
       " ('괄시', 0),\n",
       " ('토오', 0),\n",
       " ('지압', 0),\n",
       " ('랔빈', 0),\n",
       " ('츄캬해', 0),\n",
       " ('락어', 0),\n",
       " ('촉호', 0),\n",
       " ('홒홚홡환홤홢홚', 0),\n",
       " ('땀맨', 0),\n",
       " ('홰', 0),\n",
       " ('힘좀', 0),\n",
       " ('게라', 0),\n",
       " ('임산물', 0),\n",
       " ('야님', 0),\n",
       " ('왜군', 0),\n",
       " ('무당산', 0),\n",
       " ('텐씨씨', 0),\n",
       " ('구경만', 0),\n",
       " ('롯카', 0),\n",
       " ('점액', 0),\n",
       " ('문재인', 0),\n",
       " ('공범', 0),\n",
       " ('탐광', 0),\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
